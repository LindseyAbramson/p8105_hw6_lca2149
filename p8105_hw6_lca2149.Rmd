---
title: "p8105_hw6_lca2149"
output: github_document
date: "2025-11-30"
---

```{r setup, include=FALSE}
library(tidyverse)
library(dplyr)
library(readxl)
library(haven)
library(broom)
library(knitr)
library(modelr)
library(purrr)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.asp = .6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 1
```{r}
#Import and clean data
homicide_df =
  read.csv("data/homicide-data.csv") |>
mutate(
    city_state = paste(city, state, sep = ", "),
    case_closed = ifelse(disposition == "Closed by arrest", 1, 0),
    victim_age = as.numeric(victim_age)) |>
filter(
    !(city_state %in% c("Dallas, TX", "Phoenix, AZ", "Kansas City, MO", "Tulsa, OK", "Tulsa, AL")),
    victim_race %in% c("White", "Black"))
```

```{r}
# For baltimore only, use glm to fit a logistic regression with resolved vs unresolved as the outcome.
baltimore_df <- homicide_df |>
  filter(city_state == "Baltimore, MD") 
  
fit = glm(
  case_closed ~ victim_age + victim_sex + victim_race, data = baltimore_df,
family=binomial()
)


results <- tidy(fit, exponentiate = TRUE, conf.int = TRUE)|>
    knitr::kable()
results
```

The adjusted OR for solving homicides comparing male victims to female victims keeping all other variables fixed:
victim_sexMale estimate = 0.43 (95% CI: 0.32 - 0.56). 

```{r}
# Run lgm for each of the cities in our dataset, extract adjusted OR for solving homicides comparing male victims to female victims.
city_results <-
  homicide_df |>
  group_by(city_state) |>
  nest() |>
  mutate(
    fit = map(data, ~ glm(
      case_closed ~ victim_age + victim_sex + victim_race,
      data = .x,
      family = binomial
    )),
    tidy_fit = map(fit, ~ tidy(.x, exponentiate = TRUE, conf.int = TRUE))
  ) |>
  unnest(tidy_fit) |>
  filter(term == "victim_sexMale") |>   
  select(
    city_state,
    or = estimate,
    conf.low,
    conf.high,
    p.value
  )

city_results |>
   knitr::kable()
```

```{r}
# Make Plots
ggplot(city_results, aes(x=reorder(city_state, or), y=or)) + geom_point() + geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0) +
  coord_flip() +
  labs(x = "City", y = "OR (Male vs Female)") 
```


## Problem 2

```{r}
# Import Datasets
library(p8105.datasets)
data("weather_df")
```

```{r}
# Write a function
boot_estimates = function(df) {
  
  fit = lm(tmax ~ tmin + prcp, data = df)
  
  broom_coef = tidy(fit)
  broom_glance = glance(fit)
  
  beta1 = broom_coef$estimate[broom_coef$term == "tmin"]
  beta2 = broom_coef$estimate[broom_coef$term == "prcp"]
  
  tibble(
    r2 = broom_glance$r.squared,
    beta_product = beta1 * beta2
  )
}
```

```{r}
set.seed(1)

boot_results =
  tibble(iter = 1:5000) |>
  mutate(
    strap = map(iter, ~ sample_frac(weather_df, replace = TRUE)),
results = map(strap, boot_estimates)) |>
  select(-strap) |>
  unnest(results)
```

```{r}
# Plot the distributions
boot_results |>
  ggplot(aes(x=r2)) +
  geom_histogram() +
  labs(title = "Bootstrap Distribution of R Squared")
```
The boostrap distribution of R squared is very tight and unimodal, centered around ~0.940. This indicates that there is very little uncertaintly and r squared is very stable for this dataset.

```{r}
boot_results |>
  ggplot(aes(x=beta_product)) +
  geom_histogram() +
  labs(title = "Boostrap Distribution of Beta 1 and 2")
```
The beta product distribution is consistently negative and fairly tightly clustered, meaning this relationship is stable and not very sensitive to sampling variation.

```{r}
ci_r2 =
  boot_results %>%
  summarize(
    lower = quantile(r2, 0.025),
    upper = quantile(r2, 0.975)
  )
```
95% CI (0.934 - 0.947)


```{r}
ci_beta_product =
  boot_results %>%
  summarize(
    lower = quantile(beta_product, 0.025),
    upper = quantile(beta_product, 0.975)
  )
```
95% CI (-0.008-0.004)


## Problem 3
```{r}
# Import and Clean Data
birthweight_df =
  read.csv("data/birthweight.csv") |>
  janitor::clean_names()


# Clean and prepare variables
birthweight_df = 
  birthweight_df |> 
  mutate(
    babysex = factor(babysex, levels = c(1, 2), labels = c("male", "female")),
    malform = factor(malform, levels = c(0, 1), labels = c("absent", "present")),
    mrace = factor(mrace,
                   levels = c(1, 2, 3, 4, 8),
                   labels = c("white", "black", "asian", "puerto_rican", "other")),
    frace = factor(frace,
                   levels = c(1, 2, 3, 4, 8, 9),
                   labels = c("white", "black", "asian", "puerto_rican", "other", "unknown"))
  )

# Check for missing data
birthweight_df |> 
  summarize(across(everything(), ~sum(is.na(.))))
```
I imported and cleaned the data, converting some cateogical numeric variables to factors and confirmed that there was no missing data. 

```{r}
# Propose a model
bw_model = lm(bwt ~ gaweeks + momage + ppbmi + ppwt + smoken,
              data = birthweight_df)

summary(bw_model)
```
I built this model by including factors I know influence birthweight such as maternal health, lifestyle, and genetic factors. I chose a model focusing on maternal characteristics and behaviors that are biologically linked to fetal growth. I found that gestational age was by far the greatest predictor of birthweight. Maternal age and weight increased birthweight, while smoking and higher BMI decreased it. 

```{r}
# Residuals vs Fitted Plot
birthweight_df |> 
  add_predictions(bw_model) |> 
  add_residuals(bw_model) |> 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha=0.4) +
  labs(
    title = "Residuals vs Fitted Values",
    x = "Fitted Values",
    y = "Residuals"
  ) 
```

```{r}
# Comparing my model to two others
bw_model2 = lm(bwt ~ blength + gaweeks,
              data = birthweight_df)
summary(bw_model2)

bw_model3 = lm(bwt ~ bhead * blength * babysex,
                data = birthweight_df) 
summary(bw_model3)
```

```{r}
# Compare models
set.seed(1)
cv_df <- crossv_mc(birthweight_df, 100)

# Model 1 CV RMSE
cv_df <- cv_df |> 
  mutate(
    mod1 = map(train, ~ lm(bwt ~ gaweeks + momage + pnumlbw + ppbmi + ppwt + smoken, 
                           data = .x)),
    rmse_mod1 = map2_dbl(mod1, test, ~ rmse(.x, .y))
  )

# Model 2 CV RMSE
cv_df <- cv_df |> 
  mutate(
    mod2 = map(train, ~ lm(bwt ~ blength + gaweeks, data = .x)),
    rmse_mod2 = map2_dbl(mod2, test, ~ rmse(.x, .y))
  )

# Model 3 CV RMSE
cv_df <- cv_df |> 
  mutate(
    mod3 = map(train, ~ lm(bwt ~ bhead * blength * babysex, data = .x)),
    rmse_mod3 = map2_dbl(mod3, test, ~ rmse(.x, .y))
  )

cv_results <- cv_df |> 
  summarise(
    mean_rmse_mod1 = mean(rmse_mod1),
    mean_rmse_mod2 = mean(rmse_mod2),
    mean_rmse_mod3 = mean(rmse_mod3)
  )

cv_results
```
As we can see, model three has the lowest RMSE and is therefore the most accurate. As expected, more detailed measurements and interactions improve predictive accuracy. 
